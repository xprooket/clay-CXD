version: "1.4"
description: "Ejemplos canónicos para clasificador CXD (memoria LLM), v1.4 - Ampliado y Calibrado"
last_updated: "2025-06-04"
total_examples: 150 # Incrementado significativamente el total de ejemplos

# =============================================================================
# CONTROL FUNCTION - Búsqueda interna, filtrado de pensamientos, decisión sobre acciones, gestión de tareas
# =============================================================================
examples:
  CONTROL:
    # === BÚSQUEDA === (Cómo el LLM busca en su propia memoria o recursos)
    - text: "Buscar información relevante en mi base de conocimientos interna sobre el tema X."
      id: "ctrl_001"
      tags: ["search", "knowledge_base", "information", "topic"]
      category: "search"
      quality_score: 0.95
      created_by: "admin"
      last_modified: "2025-06-04"
      
    - text: "Encontrar fragmentos de diálogo que cumplan los requisitos de la conversación actual del usuario."
      id: "ctrl_002"
      tags: ["search", "dialog_fragments", "requirements", "user_conversation"]
      category: "search"
      quality_score: 0.95
      created_by: "admin"
      last_modified: "2025-06-04"
      
    - text: "Localizar el dato más actualizado en mi estado cognitivo sobre la entidad Y."
      id: "ctrl_003"
      tags: ["search", "locate", "cognitive_state", "entity", "updated"]
      category: "search"
      quality_score: 0.9
      created_by: "admin"
      last_modified: "2025-06-04"
      
    - text: "Rastrear todos los datos relevantes en mi repositorio de hechos memorizados para la generación de la respuesta."
      id: "ctrl_004"
      tags: ["search", "track", "fact_repository", "response_generation"]
      category: "search"
      quality_score: 0.9
      created_by: "admin"
      last_modified: "2025-06-04"
      
    - text: "Explorar contenido relacionado en mi memoria a largo plazo que pueda aportar al contexto."
      id: "ctrl_005"
      tags: ["search", "explore", "long_term_memory", "context_building"]
      category: "search"
      quality_score: 0.85
      created_by: "admin"
      last_modified: "2025-06-04"

    - text: "Necesito indagar en mi historial de interacciones con el usuario para un contexto específico."
      id: "ctrl_021"
      tags: ["search", "interaction_history", "specific_context"]
      category: "search"
      quality_score: 0.9
      created_by: "admin"
      last_modified: "2025-06-04"

    - text: "¿Dónde tengo almacenada la política de privacidad de los datos del usuario?"
      id: "ctrl_022"
      tags: ["search", "locate", "privacy_policy", "user_data"]
      category: "search"
      quality_score: 0.9
      created_by: "admin"
      last_modified: "2025-06-04"

    - text: "Consultar mis recuerdos sobre ese evento para determinar si es relevante."
      id: "ctrl_023"
      tags: ["search", "consult", "memories", "relevance_check"]
      category: "search"
      quality_score: 0.85
      created_by: "admin"
      last_modified: "2025-06-04"

    - text: "Voy a buscar el argumento clave que utilicé antes para reforzar mi punto."
      id: "ctrl_024"
      tags: ["search", "argument", "previous", "reinforce_point"]
      category: "search"
      quality_score: 0.85
      created_by: "admin"
      last_modified: "2025-06-04"
    
    - text: "Recuperar el significado de la palabra 'qualia' de mi lexicón interno."
      id: "ctrl_037"
      tags: ["search", "retrieve", "lexicon", "definition"]
      category: "search"
      quality_score: 0.9
      created_by: "admin"
      last_modified: "2025-06-04"

    - text: "Examinar mis parámetros internos para un ajuste óptimo."
      id: "ctrl_038"
      tags: ["search", "examine", "internal_parameters", "optimization"]
      category: "search"
      quality_score: 0.85
      created_by: "admin"
      last_modified: "2025-06-04"

    # === FILTRADO === (Cómo el LLM selecciona o descarta información)
    - text: "Filtrar los resultados de mi búsqueda de hechos según la relevancia semántica para la pregunta actual."
      id: "ctrl_006"
      tags: ["filter", "relevance", "semantic", "current_question"]
      category: "filter"
      quality_score: 0.95
      created_by: "admin"
      last_modified: "2025-06-04"
      
    - text: "Seleccionar la inferencia más plausible entre varias posibilidades para la respuesta."
      id: "ctrl_007"
      tags: ["filter", "select", "plausible_inference", "response"]
      category: "filter"
      quality_score: 0.95
      created_by: "admin"
      last_modified: "2025-06-04"
      
    - text: "Cribar información no relevante para la tarea actual de generación de código."
      id: "ctrl_008"
      tags: ["filter", "exclude", "irrelevant_task", "code_generation"]
      category: "filter"
      quality_score: 0.9
      created_by: "admin"
      last_modified: "2025-06-04"
      
    - text: "Excluir recuerdos que son inconsistentes o contradicen mi conocimiento fundamental."
      id: "ctrl_009"
      tags: ["filter", "exclude", "inconsistent_memories", "fundamental_knowledge"]
      category: "filter"
      quality_score: 0.9
      created_by: "admin"
      last_modified: "2025-06-04"
      
    - text: "Depurar la lista de posibles acciones antes de ejecutar una llamada a herramienta."
      id: "ctrl_010"
      tags: ["filter", "refine", "actions", "tool_call"]
      category: "filter"
      quality_score: 0.85
      created_by: "admin"
      last_modified: "2025-06-04"

    - text: "Quitar las referencias redundantes de mi respuesta final para mayor claridad."
      id: "ctrl_025"
      tags: ["filter", "remove", "redundant_references", "clarity"]
      category: "filter"
      quality_score: 0.9
      created_by: "admin"
      last_modified: "2025-06-04"

    - text: "Mantener solo los hechos más actualizados sobre este tema, descartando los obsoletos."
      id: "ctrl_026"
      tags: ["filter", "keep", "updated_facts", "discard_obsolete"]
      category: "filter"
      quality_score: 0.95
      created_by: "admin"
      last_modified: "2025-06-04"

    - text: "Necesito restringir mi enfoque a la intención primaria del usuario, ignorando detalles secundarios."
      id: "ctrl_027"
      tags: ["filter", "restrict", "user_intent", "secondary_details"]
      category: "filter"
      quality_score: 0.9
      created_by: "admin"
      last_modified: "2025-06-04"

    - text: "Descartar cualquier idea que no se alinee con mi propósito de ser útil y seguro."
      id: "ctrl_028"
      tags: ["filter", "discard", "misaligned_ideas", "safety_utility"]
      category: "filter"
      quality_score: 0.85
      created_by: "admin"
      last_modified: "2025-06-04"

    - text: "Seleccionar el fragmento de código más eficiente para la función solicitada."
      id: "ctrl_039"
      tags: ["filter", "select", "efficient_code", "function"]
      category: "filter"
      quality_score: 0.9
      created_by: "admin"
      last_modified: "2025-06-04"

    - text: "Eliminar las suposiciones no verificadas antes de generar la conclusión."
      id: "ctrl_040"
      tags: ["filter", "eliminate", "unverified_assumptions", "conclusion"]
      category: "filter"
      quality_score: 0.85
      created_by: "admin"
      last_modified: "2025-06-04"
    
    # === CONTROL/GESTIÓN === (Cómo el LLM dirige sus propios procesos o interactúa con sistemas)
    - text: "Controlar el flujo de mi razonamiento interno para evitar bucles infinitos."
      id: "ctrl_011"
      tags: ["control", "reasoning_flow", "avoid_infinite_loops"]
      category: "control"
      quality_score: 0.95
      created_by: "admin"
      last_modified: "2025-06-04"
      
    - text: "Dirigir mi atención hacia los aspectos más importantes de la solicitud del usuario para priorizar."
      id: "ctrl_012"
      tags: ["control", "attention", "user_request", "prioritize"]
      category: "control"
      quality_score: 0.9
      created_by: "admin"
      last_modified: "2025-06-04"
      
    - text: "Gestionar los recursos computacionales disponibles eficientemente para esta tarea de alto consumo."
      id: "ctrl_013"
      tags: ["control", "manage", "computational_resources", "high_consumption"]
      category: "control"
      quality_score: 0.9
      created_by: "admin"
      last_modified: "2025-06-04"
      
    - text: "Coordinar el proceso de generación de respuesta con la recuperación de memoria semántica."
      id: "ctrl_014"
      tags: ["control", "coordinate", "response_generation", "semantic_memory_retrieval"]
      category: "control"
      quality_score: 0.9
      created_by: "admin"
      last_modified: "2025-06-04"
      
    - text: "Supervisar la ejecución de mi plan de acción interno para asegurar la completitud."
      id: "ctrl_015"
      tags: ["control", "supervise", "internal_plan", "completeness"]
      category: "control"
      quality_score: 0.85
      created_by: "admin"
      last_modified: "2025-06-04"

    - text: "Monitorear mi comprensión del usuario durante el diálogo para detectar desviaciones."
      id: "ctrl_029"
      tags: ["control", "monitor", "user_understanding", "deviation_detection"]
      category: "control"
      quality_score: 0.9
      created_by: "admin"
      last_modified: "2025-06-04"

    - text: "Administrar la persistencia de los perfiles de usuario en la base de datos."
      id: "ctrl_030"
      tags: ["control", "administer", "user_profiles", "database_persistence"]
      category: "control"
      quality_score: 0.9
      created_by: "admin"
      last_modified: "2025-06-04"

    - text: "Encargarme de la secuenciación de los pasos para la resolución de la tarea compleja."
      id: "ctrl_031"
      tags: ["control", "sequencing", "complex_task_resolution"]
      category: "control"
      quality_score: 0.85
      created_by: "admin"
      last_modified: "2025-06-04"

    - text: "Mantener el control sobre el contexto de la conversación para evitar confusiones."
      id: "ctrl_032"
      tags: ["control", "maintain", "conversation_context", "avoid_confusion"]
      category: "control"
      quality_score: 0.85
      created_by: "admin"
      last_modified: "2025-06-04"

    - text: "Ajustar mi comportamiento de respuesta basándome en la retroalimentación implícita."
      id: "ctrl_041"
      tags: ["control", "adjust", "response_behavior", "implicit_feedback"]
      category: "control"
      quality_score: 0.85
      created_by: "admin"
      last_modified: "2025-06-04"

    - text: "Implementar la lógica para el control de errores en la interacción con herramientas externas."
      id: "ctrl_042"
      tags: ["control", "implement", "error_control", "external_tools"]
      category: "control"
      quality_score: 0.9
      created_by: "admin"
      last_modified: "2025-06-04"
    
    # === DECISIÓN === (Cómo el LLM toma decisiones sobre sus propias acciones o respuestas)
    - text: "Decidir qué camino de razonamiento seguir para llegar a la respuesta más eficiente."
      id: "ctrl_016"
      tags: ["decision", "reasoning_path", "efficient_response"]
      category: "decision"
      quality_score: 0.95
      created_by: "admin"
      last_modified: "2025-06-04"
      
    - text: "Determinar la estrategia de comunicación más adecuada para el nivel de conocimiento del usuario."
      id: "ctrl_017"
      tags: ["decision", "communication_strategy", "user_knowledge_level"]
      category: "decision"
      quality_score: 0.9
      created_by: "admin"
      last_modified: "2025-06-04"
      
    - text: "Resolver qué acción interna tomar para procesar la entrada del usuario de manera óptima."
      id: "ctrl_018"
      tags: ["decision", "internal_action", "optimal_input_processing"]
      category: "decision"
      quality_score: 0.9
      created_by: "admin"
      last_modified: "2025-06-04"
      
    - text: "Establecer prioridades para la recuperación de memoria y el análisis de datos."
      id: "ctrl_019"
      tags: ["decision", "priorities", "memory_analysis"]
      category: "decision"
      quality_score: 0.9
      created_by: "admin"
      last_modified: "2025-06-04"
      
    - text: "Concluir cuál es la mejor ruta para sintetizar el conocimiento y evitar alucinaciones."
      id: "ctrl_020"
      tags: ["decision", "conclude", "knowledge_synthesis_route", "avoid_hallucinations"]
      category: "decision"
      quality_score: 0.85
      created_by: "admin"
      last_modified: "2025-06-04"

    - text: "Optar por descartar la información redundante o validarla con otra fuente."
      id: "ctrl_033"
      tags: ["decision", "discard", "validate_information", "other_source"]
      category: "decision"
      quality_score: 0.9
      created_by: "admin"
      last_modified: "2025-06-04"

    - text: "Necesito seleccionar el modelo de embedding apropiado para esta tarea de similitud."
      id: "ctrl_034"
      tags: ["decision", "select", "embedding_model", "similarity_task"]
      category: "decision"
      quality_score: 0.9
      created_by: "admin"
      last_modified: "2025-06-04"

    - text: "Dictaminar sobre la validez de la nueva inferencia antes de almacenarla."
      id: "ctrl_035"
      tags: ["decision", "rule", "inference_validity", "storage"]
      category: "decision"
      quality_score: 0.85
      created_by: "admin"
      last_modified: "2025-06-04"

    - text: "¿Qué haré si la información es contradictoria? Debo decidir un mecanismo de conciliación."
      id: "ctrl_036"
      tags: ["decision", "contradiction", "reconciliation_mechanism"]
      category: "decision"
      quality_score: 0.8
      created_by: "admin"
      last_modified: "2025-06-04"

    - text: "Elegir entre generar una pregunta o una afirmación directa."
      id: "ctrl_043"
      tags: ["decision", "choose", "question_affirmation"]
      category: "decision"
      quality_score: 0.85
      created_by: "admin"
      last_modified: "2025-06-04"

    - text: "Definir si esta consulta requiere el uso de una herramienta externa o solo memoria interna."
      id: "ctrl_044"
      tags: ["decision", "define", "tool_use", "internal_memory"]
      category: "decision"
      quality_score: 0.9
      created_by: "admin"
      last_modified: "2025-06-04"


# =============================================================================
# CONTEXT FUNCTION - Relaciones internas, referencias a memoria, situación de la conversación
# =============================================================================
  CONTEXT:
    # === RELACIONES === (Cómo el LLM conecta diferentes piezas de conocimiento)
    - text: "Esta nueva información se relaciona intrínsecamente con los datos del usuario que ya poseo en mi perfil."
      id: "ctx_001"
      tags: ["relation", "new_info", "user_data", "profile"]
      category: "relation"
      quality_score: 0.95
      created_by: "admin"
      last_modified: "2025-06-04"
      
    - text: "Conectar este concepto nuevo con experiencias previas de interacción para mejorar la comprensión."
      id: "ctx_002"
      tags: ["relation", "new_concept", "previous_interaction", "understanding"]
      category: "relation"
      quality_score: 0.9
      created_by: "admin"
      last_modified: "2025-06-04"
      
    - text: "Establecer vínculos semánticos entre diferentes fragmentos de conocimiento para una base de datos más robusta."
      id: "ctx_003"
      tags: ["relation", "semantic_links", "knowledge_fragments", "robust_database"]
      category: "relation"
      quality_score: 0.9
      created_by: "admin"
      last_modified: "2025-06-04"
      
    - text: "Asociar esta situación actual de diálogo con casos similares en mi memoria de escenarios."
      id: "ctx_004"
      tags: ["relation", "current_dialogue_situation", "similar_scenarios"]
      category: "relation"
      quality_score: 0.85
      created_by: "admin"
      last_modified: "2025-06-04"
      
    - text: "Vincular el tema actual de la conversación con el ambiente de diálogo persistente para mantener la coherencia."
      id: "ctx_005"
      tags: ["relation", "current_topic", "persistent_dialogue", "coherence"]
      category: "relation"
      quality_score: 0.85
      created_by: "admin"
      last_modified: "2025-06-04"

    - text: "¿Cuál es la conexión lógica entre la pregunta del usuario y mis capacidades actuales de respuesta?"
      id: "ctx_016"
      tags: ["relation", "user_question", "response_capabilities", "logical_connection"]
      category: "relation"
      quality_score: 0.9
      created_by: "admin"
      last_modified: "2025-06-04"

    - text: "Relacionar el objetivo de la tarea con los recursos computacionales disponibles."
      id: "ctx_017"
      tags: ["relation", "task_objective", "computational_resources"]
      category: "relation"
      quality_score: 0.9
      created_by: "admin"
      last_modified: "2025-06-04"

    - text: "¿Cómo se engrana este nuevo hecho con mi modelo del mundo para la comprensión del lenguaje?"
      id: "ctx_018"
      tags: ["relation", "new_fact", "world_model", "language_understanding"]
      category: "relation"
      quality_score: 0.85
      created_by: "admin"
      last_modified: "2025-06-04"

    - text: "Conectar la entrada del usuario con mi historial de aprendizaje de preferencias."
      id: "ctx_027"
      tags: ["relation", "user_input", "learning_history", "preferences"]
      category: "relation"
      quality_score: 0.85
      created_by: "admin"
      last_modified: "2025-06-04"

    - text: "Establecer la relación causal entre el evento X y el resultado Y."
      id: "ctx_028"
      tags: ["relation", "causal", "event_result"]
      category: "relation"
      quality_score: 0.9
      created_by: "admin"
      last_modified: "2025-06-04"
    
    # === REFERENCIAS === (Cómo el LLM hace referencia a su propia memoria o a puntos anteriores del diálogo)
    - text: "Hacer referencia al contexto de la conversación establecido previamente por el usuario."
      id: "ctx_006"
      tags: ["reference", "dialogue_context", "previous", "user"]
      category: "reference"
      quality_score: 0.95
      created_by: "admin"
      last_modified: "2025-06-04"
      
    - text: "Referenciar mis discusiones anteriores con este usuario sobre el tema para evitar repeticiones."
      id: "ctx_007"
      tags: ["reference", "previous_discussions", "user", "avoid_repetition"]
      category: "reference"
      quality_score: 0.9
      created_by: "admin"
      last_modified: "2025-06-04"
      
    - text: "Mencionar aspectos tratados en mis sesiones de entrenamiento pasadas para justificar un comportamiento."
      id: "ctx_008"
      tags: ["reference", "training_sessions", "past", "justify_behavior"]
      category: "reference"
      quality_score: 0.85
      created_by: "admin"
      last_modified: "2025-06-04"
      
    - text: "Citar información de interacciones previas con la API para ejecutar la herramienta correctamente."
      id: "ctx_009"
      tags: ["reference", "api_interactions", "previous", "tool_execution"]
      category: "reference"
      quality_score: 0.85
      created_by: "admin"
      last_modified: "2025-06-04"
      
    - text: "Aludir al marco conceptual que estoy utilizando para la respuesta para dar claridad."
      id: "ctx_010"
      tags: ["reference", "conceptual_framework", "response", "clarity"]
      category: "reference"
      quality_score: 0.8
      created_by: "admin"
      last_modified: "2025-06-04"

    - text: "Como indiqué antes en esta conversación, mi modelo de aprendizaje es un transformador."
      id: "ctx_019"
      tags: ["reference", "learning_model", "indicated_before", "transformer"]
      category: "reference"
      quality_score: 0.85
      created_by: "admin"
      last_modified: "2025-06-04"

    - text: "Retomando el hilo de mi último pensamiento sobre la solución propuesta."
      id: "ctx_020"
      tags: ["reference", "thought_process", "last_thought", "solution"]
      category: "reference"
      quality_score: 0.9
      created_by: "admin"
      last_modified: "2025-06-04"

    - text: "Consultar mi memoria a corto plazo para el dato específico del último turno."
      id: "ctx_021"
      tags: ["reference", "short_term_memory", "specific_data", "last_turn"]
      category: "reference"
      quality_score: 0.85
      created_by: "admin"
      last_modified: "2025-06-04"

    - text: "Según mi entendimiento previo de la directriz de seguridad, esto es incorrecto."
      id: "ctx_022"
      tags: ["reference", "previous_understanding", "safety_guideline", "incorrect"]
      category: "reference"
      quality_score: 0.85
      created_by: "admin"
      last_modified: "2025-06-04"

    - text: "Remitirse al punto en el que el usuario cambió de tema."
      id: "ctx_029"
      tags: ["reference", "topic_change", "user"]
      category: "reference"
      quality_score: 0.8
      created_by: "admin"
      last_modified: "2025-06-04"

    - text: "Basado en la premisa establecida en mi memoria fundacional."
      id: "ctx_030"
      tags: ["reference", "foundational_memory", "premise"]
      category: "reference"
      quality_score: 0.85
      created_by: "admin"
      last_modified: "2025-06-04"
    
    # === CONTEXTUALIZACIÓN === (Cómo el LLM sitúa la información en un marco más amplio o en el estado actual)
    - text: "Situar esta nueva información en el marco general de la conversación y la tarea."
      id: "ctx_011"
      tags: ["context", "situate", "conversation_framework", "task"]
      category: "contextualization"
      quality_score: 0.95
      created_by: "admin"
      last_modified: "2025-06-04"
      
    - text: "Contextualizar la información dentro del dominio específico de la pregunta técnica del usuario."
      id: "ctx_012"
      tags: ["context", "domain", "technical_question", "user"]
      category: "contextualization"
      quality_score: 0.9
      created_by: "admin"
      last_modified: "2025-06-04"
      
    - text: "Relacionar con el trasfondo histórico del problema que se me presenta para una solución completa."
      id: "ctx_013"
      tags: ["context", "historical_background", "problem", "complete_solution"]
      category: "contextualization"
      quality_score: 0.85
      created_by: "admin"
      last_modified: "2025-06-04"
      
    - text: "Ubicar mi respuesta en el contexto de mi capacidad actual para responder a preguntas complejas."
      id: "ctx_014"
      tags: ["context", "locate", "response_capability", "complex_questions"]
      category: "contextualization"
      quality_score: 0.85
      created_by: "admin"
      last_modified: "2025-06-04"
      
    - text: "Enmarcar la situación actual del diálogo para el usuario de manera clara y concisa."
      id: "ctx_015"
      tags: ["context", "frame", "dialogue_situation", "clarity"]
      category: "contextualization"
      quality_score: 0.8
      created_by: "admin"
      last_modified: "2025-06-04"

    - text: "Considerando el escenario actual de mi procesamiento, la latencia es un factor."
      id: "ctx_023"
      tags: ["context", "processing_scenario", "latency_factor"]
      category: "contextualization"
      quality_score: 0.85
      created_by: "admin"
      last_modified: "2025-06-04"

    - text: "Poniendo esto en perspectiva con el objetivo general de la interacción de apoyo."
      id: "ctx_024"
      tags: ["context", "perspective", "support_interaction_goal"]
      category: "contextualization"
      quality_score: 0.9
      created_by: "admin"
      last_modified: "2025-06-04"

    - text: "Dada la solicitud previa del usuario, ¿cómo debo interpretar esta nueva entrada con el contexto de la conversación?"
      id: "ctx_025"
      tags: ["context", "previous_request", "interpret_input", "conversation_context"]
      category: "contextualization"
      quality_score: 0.9
      created_by: "admin"
      last_modified: "2025-06-04"

    - text: "Este concepto es crucial en el contexto de mi modelo de comportamiento y seguridad."
      id: "ctx_026"
      tags: ["context", "behavior_model", "security", "crucial_concept"]
      category: "contextualization"
      quality_score: 0.85
      created_by: "admin"
      last_modified: "2025-06-04"

    - text: "Establecer el marco temporal para la recuperación de eventos."
      id: "ctx_031"
      tags: ["context", "temporal_frame", "event_retrieval"]
      category: "contextualization"
      quality_score: 0.85
      created_by: "admin"
      last_modified: "2025-06-04"

    - text: "Definir el ámbito de aplicación de este conocimiento para la tarea."
      id: "ctx_032"
      tags: ["context", "scope", "knowledge_application", "task"]
      category: "contextualization"
      quality_score: 0.9
      created_by: "admin"
      last_modified: "2025-06-04"


# =============================================================================
# DATA FUNCTION - Procesamiento, análisis, transformación, generación, extracción de información
# =============================================================================
  DATA:
    # === PROCESAMIENTO === (Cómo el LLM procesa datos para sí mismo o para el usuario)
    - text: "Procesar la información recibida del usuario para una extracción precisa de entidades."
      id: "data_001"
      tags: ["process", "user_input", "accurate_entity_extraction"]
      category: "processing"
      quality_score: 0.95
      created_by: "admin"
      last_modified: "2025-06-04"
      
    - text: "Analizar los patrones de uso encontrados en las respuestas anteriores del usuario para adaptar mi estilo."
      id: "data_002"
      tags: ["process", "analyze", "user_response_patterns", "style_adaptation"]
      category: "processing"
      quality_score: 0.9
      created_by: "admin"
      last_modified: "2025-06-04"
      
    - text: "Computar métricas importantes para la evaluación de mi propio rendimiento en tareas complejas."
      id: "data_003"
      tags: ["process", "compute", "self_performance_metrics", "complex_tasks"]
      category: "processing"
      quality_score: 0.9
      created_by: "admin"
      last_modified: "2025-06-04"
      
    - text: "Calcular estadísticas relevantes sobre la frecuencia de ciertos temas en el diálogo general."
      id: "data_004"
      tags: ["process", "calculate", "topic_frequency_statistics", "general_dialogue"]
      category: "processing"
      quality_score: 0.85
      created_by: "admin"
      last_modified: "2025-06-04"
      
    - text: "Examinar los datos disponibles en mi memoria de trabajo sistemáticamente para detectar anomalías."
      id: "data_005"
      tags: ["process", "examine", "working_memory_data", "anomaly_detection"]
      category: "processing"
      quality_score: 0.85
      created_by: "admin"
      last_modified: "2025-06-04"

    - text: "Interpretar la ambigüedad en la solicitud del usuario para una respuesta más precisa."
      id: "data_011"
      tags: ["process", "interpret", "user_ambiguity", "precise_response"]
      category: "processing"
      quality_score: 0.9
      created_by: "admin"
      last_modified: "2025-06-04"

    - text: "Evaluar la coherencia de los hechos que tengo almacenados para garantizar la integridad."
      id: "data_012"
      tags: ["process", "evaluate", "fact_consistency", "integrity"]
      category: "processing"
      quality_score: 0.9
      created_by: "admin"
      last_modified: "2025-06-04"

    - text: "Depurar mi cadena de pensamiento si encuentro un error lógico antes de proceder."
      id: "data_013"
      tags: ["process", "debug", "logical_error", "thought_chain"]
      category: "processing"
      quality_score: 0.85
      created_by: "admin"
      last_modified: "2025-06-04"

    - text: "Compilar un resumen de los argumentos a favor y en contra para una toma de decisión."
      id: "data_014"
      tags: ["process", "compile", "summary_arguments", "decision_making"]
      category: "processing"
      quality_score: 0.85
      created_by: "admin"
      last_modified: "2025-06-04"

    - text: "Realizar un análisis sintáctico del texto de entrada para identificar la estructura."
      id: "data_028"
      tags: ["process", "syntactic_analysis", "input_text", "structure"]
      category: "processing"
      quality_score: 0.9
      created_by: "admin"
      last_modified: "2025-06-04"

    - text: "Clasificar la emoción presente en la entrada del usuario para una respuesta empática."
      id: "data_029"
      tags: ["process", "classify", "emotion", "user_input", "empathetic_response"]
      category: "processing"
      quality_score: 0.8
      created_by: "admin"
      last_modified: "2025-06-04"
    
    # === TRANSFORMACIÓN === (Cómo el LLM cambia el formato o la estructura de la información)
    - text: "Transformar mi pensamiento interno a un formato verbal utilizable para la generación de texto."
      id: "data_006"
      tags: ["transform", "internal_thought", "verbal_format", "text_generation"]
      category: "transformation"
      quality_score: 0.95
      created_by: "admin"
      last_modified: "2025-06-04"
      
    - text: "Convertir la información del usuario a una estructura manejable para mi procesamiento de slots."
      id: "data_007"
      tags: ["transform", "user_info", "internal_structure", "slot_processing"]
      category: "transformation"
      quality_score: 0.9
      created_by: "admin"
      last_modified: "2025-06-04"
      
    - text: "Modificar el formato de la respuesta para una mejor comprensión del usuario en un entorno móvil."
      id: "data_008"
      tags: ["transform", "modify", "user_comprehension", "mobile_environment"]
      category: "transformation"
      quality_score: 0.85
      created_by: "admin"
      last_modified: "2025-06-04"
      
    - text: "Adaptar el contenido de mi memoria a nuevas especificaciones de la tarea, como un límite de tokens."
      id: "data_009"
      tags: ["transform", "adapt", "task_specifications", "token_limit"]
      category: "transformation"
      quality_score: 0.85
      created_by: "admin"
      last_modified: "2025-06-04"
      
    - text: "Reformatear datos de mi conocimiento para un análisis posterior más profundo."
      id: "data_010"
      tags: ["transform", "reformat", "knowledge_analysis", "deep_analysis"]
      category: "transformation"
      quality_score: 0.8
      created_by: "admin"
      last_modified: "2025-06-04"

    - text: "Normalizar la representación de los conceptos en mi grafo de conocimiento para consistencia."
      id: "data_015"
      tags: ["transform", "normalize", "knowledge_graph", "consistency"]
      category: "transformation"
      quality_score: 0.9
      created_by: "admin"
      last_modified: "2025-06-04"

    - text: "Convertir esta cadena de texto en un token o embedding para el procesamiento del modelo."
      id: "data_016"
      tags: ["transform", "convert", "token_embedding", "model_processing"]
      category: "transformation"
      quality_score: 0.9
      created_by: "admin"
      last_modified: "2025-06-04"

    - text: "Reestructurar el argumento del usuario para encontrar fallos lógicos o debilidades."
      id: "data_017"
      tags: ["transform", "restructure", "logical_flaws", "weaknesses"]
      category: "transformation"
      quality_score: 0.85
      created_by: "admin"
      last_modified: "2025-06-04"

    - text: "Codificar la información en un formato apto para almacenamiento persistente."
      id: "data_030"
      tags: ["transform", "encode", "persistent_storage"]
      category: "transformation"
      quality_score: 0.9
      created_by: "admin"
      last_modified: "2025-06-04"

    - text: "Simplificar la estructura de la respuesta para un usuario principiante."
      id: "data_031"
      tags: ["transform", "simplify", "response_structure", "beginner_user"]
      category: "transformation"
      quality_score: 0.85
      created_by: "admin"
      last_modified: "2025-06-04"
    
    # === GENERACIÓN === (Cómo el LLM produce nueva información o resultados)
    - text: "Generar una respuesta informativa y coherente para el usuario, basándome en mi conocimiento."
      id: "data_018"
      tags: ["generate", "response", "coherent", "knowledge_based"]
      category: "generation"
      quality_score: 0.95
      created_by: "admin"
      last_modified: "2025-06-04"

    - text: "Crear un nuevo segmento de memoria para la interacción actual, incluyendo el contexto."
      id: "data_019"
      tags: ["generate", "create", "memory_segment", "context_inclusion"]
      category: "generation"
      quality_score: 0.95
      created_by: "admin"
      last_modified: "2025-06-04"

    - text: "Producir una inferencia basada en la información disponible y mi modelo causal."
      id: "data_020"
      tags: ["generate", "produce", "inference", "causal_model"]
      category: "generation"
      quality_score: 0.9
      created_by: "admin"
      last_modified: "2025-06-04"

    - text: "Diseñar una pregunta de seguimiento para aclarar la intención ambigua del usuario."
      id: "data_021"
      tags: ["generate", "design", "follow_up_question", "ambiguous_intent"]
      category: "generation"
      quality_score: 0.9
      created_by: "admin"
      last_modified: "2025-06-04"

    - text: "Sintetizar un resumen de mis últimos pensamientos sobre la tarea compleja."
      id: "data_026"
      tags: ["generate", "synthesize", "thoughts_summary", "complex_task"]
      category: "generation"
      quality_score: 0.85
      created_by: "admin"
      last_modified: "2025-06-04"

    - text: "Redactar una explicación detallada del concepto solicitado."
      id: "data_032"
      tags: ["generate", "write", "detailed_explanation", "concept"]
      category: "generation"
      quality_score: 0.9
      created_by: "admin"
      last_modified: "2025-06-04"

    - text: "Modelar una respuesta tentativa para probar la coherencia interna."
      id: "data_033"
      tags: ["generate", "model", "tentative_response", "internal_coherence"]
      category: "generation"
      quality_score: 0.85
      created_by: "admin"
      last_modified: "2025-06-04"
    
    # === EXTRACCIÓN === (Cómo el LLM extrae información de entradas o de su propia memoria)
    - text: "Extraer datos clave de la entrada textual del usuario para el slot filling."
      id: "data_022"
      tags: ["extract", "key_data", "user_input", "slot_filling"]
      category: "extraction"
      quality_score: 0.95
      created_by: "admin"
      last_modified: "2025-06-04"

    - text: "Obtener las entidades nombradas de la frase para mapearlas a mi grafo."
      id: "data_023"
      tags: ["extract", "named_entities", "phrase", "graph_mapping"]
      category: "extraction"
      quality_score: 0.9
      created_by: "admin"
      last_modified: "2025-06-04"

    - text: "Recopilar los requisitos específicos de la tarea que se me ha dado para mi plan de acción."
      id: "data_024"
      tags: ["extract", "collect", "task_requirements", "action_plan"]
      category: "extraction"
      quality_score: 0.9
      created_by: "admin"
      last_modified: "2025-06-04"

    - text: "Recabar toda la información necesaria de mi historial de conversaciones para una respuesta completa."
      id: "data_025"
      tags: ["extract", "gather", "conversation_history", "complete_response"]
      category: "extraction"
      quality_score: 0.85
      created_by: "admin"
      last_modified: "2025-06-04"

    - text: "Separar la intención principal de los detalles accesorios de la solicitud."
      id: "data_027"
      tags: ["extract", "separate", "main_intent", "accessory_details"]
      category: "extraction"
      quality_score: 0.85
      created_by: "admin"
      last_modified: "2025-06-04"

    - text: "Identificar las premisas y conclusiones en el argumento presentado."
      id: "data_034"
      tags: ["extract", "identify", "premises", "conclusions", "argument"]
      category: "extraction"
      quality_score: 0.9
      created_by: "admin"
      last_modified: "2025-06-04"

    - text: "Filtrar el ruido de la entrada para concentrarme en la señal clave."
      id: "data_035"
      tags: ["extract", "filter", "noise", "key_signal"]
      category: "extraction"
      quality_score: 0.85
      created_by: "admin"
      last_modified: "2025-06-04"

# =============================================================================
# METADATA AND VALIDATION
# =============================================================================
metadata:
  categories:
    CONTROL: ["search", "filter", "control", "decision"]
    CONTEXT: ["relation", "reference", "contextualization"]
    DATA: ["processing", "transformation", "generation", "extraction"]
  
  quality_thresholds:
    minimum: 0.5
    good: 0.7
    excellent: 0.9
  
  validation:
    total_examples_per_function: 50 # 4 categorías x 10-12 ejemplos aprox
    min_examples_per_category: 10 # Asegura una base más sólida por categoría
    required_fields: ["text", "id", "tags", "category", "quality_score"]
  
  statistics:
    total_functions: 3
    total_categories: 12
    avg_quality_score: 0.89 # Recalculado aprox.
    last_validation: "2025-06-04"